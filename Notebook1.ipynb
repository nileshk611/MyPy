{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Pandas for Excel Automations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example1: Program to read Excel File containing various details and only fetch the URL Domain Names.\n",
    "\n",
    "Sample Excel Sheet Rows:\n",
    "v_message := v_message_temp||'<br>Click <a href=\"http://orarptprod/act_reg_disp.disp_action_reg?in_act_reg_name_id='||rec.reg_id||'\">here</a> to review action item.';\n",
    "\n",
    "htp.p('<script language=\"JavaScript\" src=\"http://tammon05.na.ten/scripts/sorttable.js\"></script>');\n",
    "\n",
    "v_message := 'The task \"'||in_desc||'\" you requested has been completed. Please click <a href=\"http://170.64.200.22:7777/pls/prod/amexh_to_do_rpt.disp_single?in_id='||in_id||'\">here</a> for more details. ';\n",
    "\n",
    "and so on ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the List\n",
      "['http://orarptprod', 'http://tammon05.na.ten', 'http://170.64.200.22:7777', 'http://na_engineering.amer.int.tenneco.com', 'http://170.64.200.22:7777', 'http://na_engineering.amer.int.tenneco.com', 'http://na_engineering.amer.int.tenneco.com', 'http://grasslake.na.ten', 'http://na_engineering.amer.int.tenneco.com', 'http://na_engineering.amer.int.tenneco.com', 'http://grasslake.na.ten', 'http://grasslake.na.ten']\n",
      "       \n",
      "Printing the dataframe\n",
      "                                          URL\n",
      "0                           http://orarptprod\n",
      "1                      http://tammon05.na.ten\n",
      "2                   http://170.64.200.22:7777\n",
      "3  http://na_engineering.amer.int.tenneco.com\n",
      "4                     http://grasslake.na.ten\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"urlsearch_test.xlsx\") #read excel file\n",
    "l = [] #Empty list used for 'for loop'\n",
    "\n",
    "#loop starts here..\n",
    "#Used try to handle exceptions\n",
    "for index, row in df.iterrows():\n",
    "    try: \n",
    "        str = (row['TEXT']) #string to read and iterate, TEXT is the Column name in Excel\n",
    "        y = (index)\n",
    "        str_pos = str.index('http') #fetched the index position for http\n",
    "        str_pos1 = str.index('/', str.index('/')+2) #fetched the second 3rd position of / starting from http\n",
    "        str_op = str[str_pos:str_pos1] #Used string slicling to only fetch the domain name\n",
    "        l.append(str_op) # keep appending the list in the for loop with the domain names\n",
    "           \n",
    "    #Error handling to skip the error rows and continue.\n",
    "    except ValueError:\n",
    "            print('Error!')\n",
    "print('Printing the List')\n",
    "print(l) #Printing the list which is created in the for loop.\n",
    "\n",
    "l = list(dict.fromkeys(l)) #Keep distinct values, you can comment this line to get all the values\n",
    "\n",
    "df1 = pd.DataFrame(l,columns=['URL']) #Create dataframe using the list\n",
    "\n",
    "print('       ')\n",
    "print('Printing the dataframe')\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example2: This program is similar to the above program which reads from the excel workbook to fetch only the URL domain names, however in this program it writes the output to the existing excel workbook in a different sheet.\n",
    "\n",
    "Sample Excel Sheet Rows:\n",
    "v_message := v_message_temp||'<br>Click <a href=\"http://orarptprod/act_reg_disp.disp_action_reg?in_act_reg_name_id='||rec.reg_id||'\">here</a> to review action item.';\n",
    "\n",
    "htp.p('<script language=\"JavaScript\" src=\"http://tammon05.na.ten/scripts/sorttable.js\"></script>');\n",
    "\n",
    "v_message := 'The task \"'||in_desc||'\" you requested has been completed. Please click <a href=\"http://170.64.200.22:7777/pls/prod/amexh_to_do_rpt.disp_single?in_id='||in_id||'\">here</a> for more details. ';\n",
    "\n",
    "and so on ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://orarptprod', 'http://tammon05.na.ten', 'http://170.64.200.22:7777', 'http://na_engineering.amer.int.tenneco.com', 'http://170.64.200.22:7777', 'http://na_engineering.amer.int.tenneco.com', 'http://na_engineering.amer.int.tenneco.com', 'http://grasslake.na.ten', 'http://na_engineering.amer.int.tenneco.com', 'http://na_engineering.amer.int.tenneco.com', 'http://grasslake.na.ten', 'http://grasslake.na.ten']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook #for writting to the existing workbook\n",
    "\n",
    "df = pd.read_excel(\"urlsearch_test.xlsx\")\n",
    "\n",
    "#You can use the below for the relative path.\n",
    "# r\"C:\\Users\\xyz\\Desktop\\Python\\\n",
    "\n",
    "l = [] #To make a list in for loop\n",
    "\n",
    "#begin\n",
    "#loop starts here for fetching http from a string and iterate thru the entire sheet. You can have your own logic here.\n",
    "for index, row in df.iterrows():\n",
    "    try: \n",
    "        str = (row['TEXT']) #string to read and iterate\n",
    "        y = (index)\n",
    "        str_pos = str.index('http') #fetched the index position for http\n",
    "        str_pos1 = str.index('/', str.index('/')+2) #fetched the second 3rd position of / starting from http\n",
    "        str_op = str[str_pos:str_pos1] #Substring the domain name\n",
    "        l.append(str_op) #append the list with domain names\n",
    "       \n",
    "    #Error handling to skip the error rows and continue.\n",
    "    except ValueError:\n",
    "            print('Error!')\n",
    "print(l)\n",
    "l = list(dict.fromkeys(l)) #Keep distinct values, you can comment this line to get all the values\n",
    "df1 = pd.DataFrame(l,columns=['URL']) #Create dataframe using the list\n",
    "#end\n",
    "\n",
    "#Write using openpyxl so it can be written to same workbook\n",
    "book = load_workbook('urlsearch_test.xlsx')\n",
    "writer = pd.ExcelWriter('urlsearch_test.xlsx',engine = 'openpyxl')\n",
    "writer.book = book\n",
    "df1.to_excel(writer,sheet_name = 'Sheet3')\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
